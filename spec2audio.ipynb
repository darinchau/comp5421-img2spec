{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla inference script\n",
    "from processing import *\n",
    "\n",
    "spec = inference(\n",
    "    model_repo=\"darinchau/comp5421-project-sage-lake-20-comp5421-mel-spectrogram-step-2560\",\n",
    "    seed = 1,\n",
    "    sample_count=1,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "audio = mel_to_audio(spec[\"latents\"][0, 0], TARGET_SR)\n",
    "audio /= np.max(np.abs(audio))\n",
    "Audio(audio, rate=TARGET_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save audio as mp3\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "wavfile.write(\"figures/output.wav\", TARGET_SR, audio)\n",
    "!ffmpeg -i figures/output.wav figures/output.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate denoising animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib\n",
    "from processing import *\n",
    "\n",
    "spec = inference(\n",
    "    model_repo=\"darinchau/comp5421-project-sage-lake-20-comp5421-mel-spectrogram-step-2560\",\n",
    "    seed = 1,\n",
    "    sample_count=1,\n",
    "    verbose=True,\n",
    "    sample_steps=100,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_mel(mel, fig, ax):\n",
    "    img = librosa.display.specshow(mel, sr=TARGET_SR, x_axis='time', y_axis='mel')\n",
    "    cb = fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "def show_mel_normalized(mel, fig, ax):\n",
    "    mel = mel.copy().clip(min=-80., max=80.)\n",
    "    mel = librosa.db_to_amplitude(mel)\n",
    "    mel_basis = librosa.filters.mel(sr=TARGET_SR, n_fft=2048, n_mels=128)\n",
    "    inv_mel_basis = np.linalg.pinv(mel_basis)\n",
    "    stft_magnitude = np.dot(inv_mel_basis, mel)\n",
    "    stft_magnitude_squared = stft_magnitude**2\n",
    "    audio = librosa.griffinlim(stft_magnitude_squared, hop_length=512, n_iter=32)\n",
    "\n",
    "    audio /= np.max(np.abs(audio))\n",
    "    stft = np.abs(librosa.stft(audio, n_fft=2048, hop_length=512))\n",
    "    mel = librosa.feature.melspectrogram(sr=TARGET_SR, S=stft**2, n_mels=128)\n",
    "    log_mel = librosa.amplitude_to_db(mel)\n",
    "    show_mel(log_mel, fig, ax)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "show_mel(spec['latents'][0, 0], fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "def make_animation():\n",
    "    os.makedirs('figures', exist_ok=True)\n",
    "    data = spec['intermediates'][0]\n",
    "    N = data.shape[0]\n",
    "\n",
    "    # Create a writer object\n",
    "    writer = imageio.get_writer('figures/animation.mp4', fps=30)\n",
    "\n",
    "    for i in range(N):\n",
    "        fig, ax = plt.subplots()\n",
    "        show_mel(data[i], fig, ax)\n",
    "        ax.set_title(f\"Step {i + 1}\")\n",
    "\n",
    "        # Save the plot as an image in memory\n",
    "        fig.canvas.draw()\n",
    "        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "        writer.append_data(image)\n",
    "        plt.close(fig)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "make_animation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "audio_path = \"D:/audio-dataset-v3/audio/dQw4w9WgXcQ.wav\"\n",
    "mel = audio2mel(audio_path)\n",
    "audio = mel_to_audio(mel, TARGET_SR)\n",
    "Audio(audio, rate=TARGET_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these two songs\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "wavfile.write(\"figures/convinput.wav\", TARGET_SR, audio)\n",
    "\n",
    "x, sr = librosa.load(audio_path, sr=TARGET_SR, mono=True)\n",
    "start, end = 0, 432*512-1\n",
    "wavfile.write(\"figures/convoutput.wav\", TARGET_SR, x[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "show_mel(mel, fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise an existing song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from processing import *\n",
    "\n",
    "audio_path = \"D:/audio-dataset-v3/audio/dQw4w9WgXcQ.wav\"\n",
    "mel = audio2mel(audio_path)\n",
    "spec = inference(\n",
    "    model_repo=\"darinchau/comp5421-project-sage-lake-20-comp5421-mel-spectrogram-step-2560\",\n",
    "    seed = 1,\n",
    "    sample_count=1,\n",
    "    verbose=True,\n",
    "    sample_steps=10,\n",
    "    sample_step_start=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(mel_to_audio(spec['latents'][0, 0], TARGET_SR), rate=TARGET_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec['latents'][0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(mel_to_audio(mel, TARGET_SR).clip(-32768, 32768), rate=TARGET_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(mel_to_audio(mel, TARGET_SR)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
